{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\an\\envs\\ece1786\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama import llama_api\n",
    "#from gpt4 import gpt4o_api\n",
    "from score import comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"example_input.txt\"\n",
    "reference_file = \"example_truth.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_prompt = \"Read the following document and write a summary that includes the background of the case in one paragraph, the procedural history in two paragraphs, and the court's decision and reasoning in one paragraph.\"\n",
    "# print(my_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the most essential parts of the case\n",
    "prompt = \"State the background of the case in one paragraph in the following document.\"\n",
    "facts = llama_api(prompt=prompt, input_file=input_file, output_file=\"llama_agent_facts.txt\")\n",
    "print(\"Facts done.\")\n",
    "\n",
    "prompt = \"Summarize the procedural history in two paragraphs in the following document.\"\n",
    "history = llama_api(prompt=prompt, input_file=input_file, output_file=\"llama_agent_history.txt\")\n",
    "print(\"history done.\")\n",
    "\n",
    "prompt = \"State the court's decision and reasoning in one paragraph in the following document.\"\n",
    "reasoning = llama_api(prompt=prompt, input_file=input_file, output_file=\"llama_agent_reasoning.txt\")\n",
    "print(\"reasoning done.\")\n",
    "\n",
    "# Get the more concise conclusions which are put at the front of the summary.\n",
    "case_summary = \"\\n\\n\".join([facts, history, reasoning])\n",
    "\n",
    "prompt = \"In one simple clause, write a concise headline that summarizes the court's decision in the following summary:\"\n",
    "decision = llama_api(prompt=prompt, text=case_summary, output_file=\"llama_agent_decision.txt\")\n",
    "print(\"decision done.\")\n",
    "\n",
    "prompt = \"In one simple sentence, write a concise legal statement that summarizes the central question in the following case summary:\"\n",
    "issue = llama_api(prompt=prompt, text=case_summary, output_file=\"llama_agent_issue.txt\")\n",
    "print(\"issue done.\")\n",
    "\n",
    "# Organize to form the final output summary.\n",
    "combined_summary = \"\\n\\n\".join([decision, issue, facts, history, reasoning])\n",
    "\n",
    "prompt = \"Combine the following pieces of text into a single cohesive passage. Ensure the flow is smooth and logical while keeping most of the original content unchanged. Edit only as needed for readability and natural transitions\"\n",
    "final_output = llama_api(prompt=prompt, text=combined_summary, output_file=\"llama_final_output.txt\")\n",
    "print(\"combine done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'llama_final_output.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcomparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama_final_output.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal_comparison.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\mie\\1786\\project\\prompt_experiments\\score.py:23\u001b[0m, in \u001b[0;36mcomparison\u001b[1;34m(reference_file, generated_file, output_score_file)\u001b[0m\n\u001b[0;32m     20\u001b[0m     reference_summary \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     22\u001b[0m generated_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     24\u001b[0m     generated_summary \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     26\u001b[0m rouge_scores \u001b[38;5;241m=\u001b[39m calculate_rouge(reference_summary, generated_summary)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'llama_final_output.txt'"
     ]
    }
   ],
   "source": [
    "comparison(reference_file, \"llama_final_output.txt\", \"final_comparison.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent_1...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LA-cafe700b5f334e16a6a1d5d07d8b76f16e4b01be7fc640e2a9e1847bb5796840'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_output.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mllama_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m generated_paragraphs[agent_name] \u001b[38;5;241m=\u001b[39m content\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed. Output saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\mie\\1786\\project\\prompt_experiments\\llama.py:8\u001b[0m, in \u001b[0;36mllama_api\u001b[1;34m(prompt, text, input_file, output_file)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_api\u001b[39m(prompt, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, input_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Initialize the SDK\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLA-cafe700b5f334e16a6a1d5d07d8b76f16e4b01be7fc640e2a9e1847bb5796840\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m     llama \u001b[38;5;241m=\u001b[39m LlamaAPI(key)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\an\\envs\\ece1786\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LA-cafe700b5f334e16a6a1d5d07d8b76f16e4b01be7fc640e2a9e1847bb5796840'"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "        \"You are an expert legal assistant specializing in summarizing court decisions. \"\n",
    "        \"Your role is to provide concise, clear, and accurate summaries of legal cases. \"\n",
    "        \"Follow these rules for every response:\\n\"\n",
    "        \"1. Use formal language appropriate for legal and professional contexts.\\n\"\n",
    "        \"2. Ensure the summary is logically structured with clear sections:\\n\"\n",
    "        \"   - Title\\n\"\n",
    "        \"   - Introduction\\n\"\n",
    "        \"   - Background\\n\"\n",
    "        \"   - Court Proceedings\\n\"\n",
    "        \"   - Legal Principle\\n\"\n",
    "        \"   - Conclusion\\n\"\n",
    "        \"3. Avoid unnecessary repetition and ensure smooth transitions between sections.\\n\"\n",
    "        \"4. Provide summaries that are understandable to non-experts while retaining legal accuracy.\"\n",
    "    )\n",
    "\n",
    "agents_prompts = {\n",
    "    \"agent_1\": (\n",
    "        \"Summarize the background of the case in one concise paragraph. Include the complainant, the accused, the alleged offences, and references to applicable sections of the Criminal Code.\"\n",
    "        \"Focus on the complainant, the accused, and the core allegations.\"\n",
    "    ),\n",
    "    \"agent_2\": (\n",
    "        \"Summarize the entire court proceedings in one concise paragraph, including: \"\n",
    "        \"- The trial process: Describe the evidence presented, the trial judge's decision, and their reasoning. \"\n",
    "        \"- The appellate process: Highlight the appellate arguments, the appellate courts' reasoning, and their decisions. \"\n",
    "        \"- The final decision: Summarize the final judgment and reasoning of the highest court involved in this case. \"\n",
    "        \"Focus on the logical progression of the case and key reasoning at each stage.\"\n",
    "    ),\n",
    "    \"agent_3\": (\n",
    "        \"Summarize the most critical legal principle established in this case in one concise sentence. \"\n",
    "        \"Focus on the general relevance of the evidence, its relationship to the legal elements of the offence, and ensure the principle can apply broadly in similar cases.\"\n",
    "    ),\n",
    "    \"agent_4\": (\n",
    "        \"Write a concluding paragraph starting with 'Writing for the'. \"\n",
    "        \"Summarize the majority opinion, focusing on the reasoning and its implications for the case.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# save results\n",
    "generated_paragraphs = {}\n",
    "\n",
    "# generate texts\n",
    "for agent_name, prompt in agents_prompts.items():\n",
    "    output_file = f\"{agent_name}_output.txt\"\n",
    "    print(f\"Running {agent_name}...\")\n",
    "    content = llama_api(\n",
    "        prompt=prompt,\n",
    "        input_file=input_file,\n",
    "        output_file=output_file\n",
    "    )\n",
    "    generated_paragraphs[agent_name] = content\n",
    "    print(f\"{agent_name} completed. Output saved to {output_file}\")\n",
    "\n",
    "agent_5_prompt = (\n",
    "    \"Combine the following text outputs from seven agents into a single cohesive and well-structured summary. \"\n",
    "    \"Follow this structure and ensure each section adheres to the specified format: \"\n",
    "    \"1. Title: Begin with the name of the court and provide a concise summary of the decision. For example, 'The Supreme Court sets aside...'. \"\n",
    "    \"2. Introduction: Write one sentence starting with 'This appeal' that summarizes the central legal question. \"\n",
    "    \"3. Background: Summarize the case facts, including the complainant, the accused, the alleged offences, and references to relevant legal provisions. \"\n",
    "    \"4. Court Proceedings: Describe the entire court process in one paragraph, including the trial, appellate decisions, and final judgment, ensuring smooth progression. \"\n",
    "    \"5. Legal Principle: Provide the most critical legal principle established by the court in one concise sentence. Ensure it is general and applicable to similar cases. \"\n",
    "    \"6. Conclusion: Write a concluding paragraph starting with 'Writing for the', summarizing the court's reasoning and its broader implications for the law. \"\n",
    "    \"- Remove all redundancy or repetition while preserving critical legal principles and facts. \"\n",
    "    \"- Ensure smooth transitions between sections, with each part contributing to a clear and logical narrative.\"\n",
    "    \"- Part 5 should be absolutely one sentence, and not include the specific cases or facts.\"\n",
    "    \"- part 6 should not be changed too much.\"\n",
    ")\n",
    "\n",
    "# combine all paragraphs\n",
    "all_paragraphs_combined = \"\\n\\n\".join(generated_paragraphs.values())\n",
    "\n",
    "# final\n",
    "final_output = llama_api(\n",
    "    prompt=agent_5_prompt,\n",
    "    text=all_paragraphs_combined,\n",
    "    output_file=\"final_case_summary_integrated.txt\"\n",
    ")\n",
    "print(\"Final integrated summary saved to final_case_summary_integrated.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent_1...\n",
      "agent_1 completed. Output saved to agent_1_output.txt\n",
      "Running agent_2...\n",
      "agent_2 completed. Output saved to agent_2_output.txt\n",
      "Running agent_3...\n",
      "agent_3 completed. Output saved to agent_3_output.txt\n",
      "Running agent_4...\n",
      "agent_4 completed. Output saved to agent_4_output.txt\n",
      "Running final integration agent...\n",
      "Final integrated summary saved to final_case_summary_integrated.txt.\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt to set the tone and role for the model\n",
    "system_prompt = (\n",
    "    \"You are an expert legal assistant specializing in summarizing court decisions. \"\n",
    "    \"Your role is to provide concise, clear, and accurate summaries of legal cases. \"\n",
    "    \"Follow these rules for every response:\\n\"\n",
    "    \"1. Use formal language appropriate for legal and professional contexts.\\n\"\n",
    "    \"2. Ensure the summary is logically structured with clear sections:\\n\"\n",
    "    \"   - Title\\n\"\n",
    "    \"   - Introduction\\n\"\n",
    "    \"   - Background\\n\"\n",
    "    \"   - Court Proceedings\\n\"\n",
    "    \"   - Legal Principle\\n\"\n",
    "    \"   - Conclusion\\n\"\n",
    "    \"3. Avoid unnecessary repetition and ensure smooth transitions between sections.\\n\"\n",
    "    \"4. Provide summaries that are understandable to non-experts while retaining legal accuracy.\"\n",
    ")\n",
    "\n",
    "# Define agent-specific prompts\n",
    "agents_prompts = {\n",
    "    \"agent_1\": (\n",
    "        \"Summarize the background of the case in one concise paragraph. \"\n",
    "        \"Include the complainant, the accused, the alleged offences, and references to applicable sections of the Criminal Code. \"\n",
    "        \"Focus on the complainant, the accused, and the core allegations.\"\n",
    "    ),\n",
    "    \"agent_2\": (\n",
    "        \"Summarize the entire court proceedings in one concise paragraph, including: \"\n",
    "        \"- The trial process: Describe the evidence presented, the trial judge's decision, and their reasoning. \"\n",
    "        \"- The appellate process: Highlight the appellate arguments, the appellate courts' reasoning, and their decisions. \"\n",
    "        \"- The final decision: Summarize the final judgment and reasoning of the highest court involved in this case. \"\n",
    "        \"Focus on the logical progression of the case and key reasoning at each stage.\"\n",
    "    ),\n",
    "    \"agent_3\": (\n",
    "        \"Summarize the most critical legal principle established in this case in one concise sentence. \"\n",
    "        \"Focus on the general relevance of the evidence, its relationship to the legal elements of the offence, and ensure the principle can apply broadly in similar cases.\"\n",
    "    ),\n",
    "    \"agent_4\": (\n",
    "        \"Write a concluding paragraph starting with 'Writing for the'. \"\n",
    "        \"Summarize the majority opinion, focusing on the reasoning and its implications for the case.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Integration agent prompt\n",
    "agent_5_prompt = (\n",
    "    \"Combine the following text outputs from four agents into a single cohesive and well-structured summary. \"\n",
    "    \"Follow this structure and ensure each section adheres to the specified format: \"\n",
    "    \"1. Title: Begin with the name of the court and provide a concise summary of the decision. For example, 'The Supreme Court sets aside...'. \"\n",
    "    \"2. Introduction: Write one sentence starting with 'This appeal' that summarizes the central legal question. \"\n",
    "    \"3. Background: Summarize the case facts, including the complainant, the accused, the alleged offences, and references to relevant legal provisions. \"\n",
    "    \"4. Court Proceedings: Describe the entire court process in one paragraph, including the trial, appellate decisions, and final judgment, ensuring smooth progression. \"\n",
    "    \"5. Legal Principle: Provide the most critical legal principle established by the court in one concise sentence. Ensure it is general and applicable to similar cases. \"\n",
    "    \"6. Conclusion: Write a concluding paragraph starting with 'Writing for the', summarizing the court's reasoning and its broader implications for the law. \"\n",
    "    \"- Remove all redundancy or repetition while preserving critical legal principles and facts. \"\n",
    "    \"- Ensure smooth transitions between sections, with each part contributing to a clear and logical narrative.\"\n",
    "    \"- Remove all the subtitles, like 'conclusion'. \"\n",
    ")\n",
    "\n",
    "# Generate text for each agent\n",
    "generated_paragraphs = {}\n",
    "\n",
    "for agent_name, prompt in agents_prompts.items():\n",
    "    output_file = f\"{agent_name}_output.txt\"\n",
    "    print(f\"Running {agent_name}...\")\n",
    "\n",
    "    # Combine system prompt and agent prompt\n",
    "    combined_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
    "    # Assume `input_file` contains case details\n",
    "    content = llama_api(\n",
    "        prompt=combined_prompt,\n",
    "        input_file=input_file,\n",
    "        output_file=output_file\n",
    "    )\n",
    "    generated_paragraphs[agent_name] = content\n",
    "    print(f\"{agent_name} completed. Output saved to {output_file}\")\n",
    "\n",
    "# Combine all agent outputs\n",
    "all_paragraphs_combined = \"\\n\\n\".join(generated_paragraphs.values())\n",
    "\n",
    "print(\"Running final integration agent...\")\n",
    "\n",
    "# Combine system prompt with integration task\n",
    "combined_integration_prompt = f\"{system_prompt}\\n\\n{agent_5_prompt}\"\n",
    "final_output = llama_api(\n",
    "    prompt=combined_integration_prompt,\n",
    "    text=all_paragraphs_combined,\n",
    "    output_file=\"final_case_summary_integrated.txt\"\n",
    ")\n",
    "print(\"Final integrated summary saved to final_case_summary_integrated.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Rick\\AppData\\Local\\Temp\\ipykernel_15896\\1909177251.py\", line 1, in <module>\n",
      "    comparison(reference_file, \"final_case_summary_integrated.txt\", \"test_score.txt\")\n",
      "  File \"e:\\mie\\1786\\project\\prompt_experiments\\score.py\", line 27, in comparison\n",
      "    bert_precision, bert_recall, bert_f1 = calculate_bertscore(reference_summary, generated_summary)\n",
      "  File \"e:\\mie\\1786\\project\\prompt_experiments\\score.py\", line 14, in calculate_bertscore\n",
      "    P, R, F1 = score([generated], [reference], lang=\"en\", verbose=True)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\bert_score\\score.py\", line 101, in score\n",
      "    model.to(device)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\transformers\\modeling_utils.py\", line 3157, in to\n",
      "    return super().to(*args, **kwargs)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1152, in to\n",
      "    return self._apply(convert)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 825, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1150, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 4.33 GiB is free. Of the allocated memory 682.89 MiB is allocated by PyTorch, and 5.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1039, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"e:\\an\\envs\\ece1786\\lib\\site-packages\\executing\\executing.py\", line 153, in __init__\n",
      "    self.text = ''.join(lines)\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "comparison(reference_file, \"final_case_summary_integrated.txt\", \"test_score.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"multi_agent_concat_results/llama_output_facts.txt\", \"r\") as file:\n",
    "#     facts = file.read()\n",
    "\n",
    "# with open(\"multi_agent_concat_results/llama_output_history.txt\", \"r\") as file:\n",
    "#     history = file.read()\n",
    "\n",
    "# with open(\"multi_agent_concat_results/llama_output_reasoning.txt\", \"r\") as file:\n",
    "#     reasoning = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the more concise conclusions which are put at the front of the summary.\n",
    "# case_summary = \"\\n\\n\".join([facts, history, reasoning])\n",
    "\n",
    "# prompt = \"In one simple clause, write a concise headline that summarizes the court's decision in the following summary:\"\n",
    "# decision = llama_api(prompt=prompt, text=case_summary, output_file=\"llama_agent_decision.txt\")\n",
    "# print(\"decision done.\")\n",
    "\n",
    "# prompt = \"In one simple sentence, write a concise legal statement that summarizes the central question in the following case summary:\"\n",
    "# issue = llama_api(prompt=prompt, text=case_summary, output_file=\"llama_agent_issue.txt\")\n",
    "# print(\"issue done.\")\n",
    "\n",
    "# # Organize to form the final output summary.\n",
    "# combined_summary = \"\\n\\n\".join([decision, issue, facts, history, reasoning])\n",
    "\n",
    "# prompt = \"Combine the following pieces of text into a single cohesive passage. Ensure the flow is smooth and logical while keeping most of the original content unchanged. Edit only as needed for readability and natural transitions\"\n",
    "# final_output = llama_api(prompt=prompt, text=combined_summary, output_file=\"llama_final_output.txt\")\n",
    "# print(\"combine done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece1786",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
